{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/10/30/hello-world/"},{"title":"Chapter_1_2_Python_visualisation_seaborn","text":"1. Matplotlib &amp; Seaborn1-1. 기본 개요Matplotlib: 파이썬 표준 시각화 도구. 파이썬 그래프의 기본 토대. 객체지향 프로그래밍을 지원하므로 세세하게 꾸밀 수 있다. Seaborn: 파이썬 시각화 도구의 고급 버전. Matplotlib에 비해 비교적 단순한 인터페이스를 제공하기 때문에 초보자도 어렵지 않게 배울 수 있다. 1-2. matplotlib &amp; Seabon 설치설치방법은 윈도우 명령 프롬프트, MacOS, Linux 터미널에서 pip install matplotlib입력하면 되지만, 간혹 여러 환경에 따라 달라질 수 있으니 관련 싸이트에서 확인하기를 바란다. matplotlib 설치 방법: https://matplotlib.org/users/installing.html seaborn 설치 방법: https://seaborn.pydata.org/installing.html 2. 기본적인 시각화 문법 시각화 문법은 아래와 같다. 12import seaborn as snssns.name_of_graph(x, y, dataset, options) 우선 Sample 데이터를 불러와서 데이터를 확인해보자. 123456import seaborn as snsfrom tabulate import tabulatesns.set()tips = sns.load_dataset(&quot;tips&quot;)print(tabulate(tips.head(), tablefmt=&quot;pipe&quot;, headers=&quot;keys&quot;)) # Hugo 블로그 전용 위 데이터는 매우 간단한 테이블일 수 있지만, 다변량의 그래프를 하나의 이미지 안에서 어떤 형태로 그래프를 작성할 것인지 선택하는 것은 쉽지 않다. 123sns.relplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, col=&quot;time&quot;, hue=&quot;sex&quot;, style=&quot;smoker&quot;, size=&quot;size&quot;, data=tips); 소스코드에 대한 설명을 간단히 하면 아래와 같다. relplot은 다변량의 그래프를 작성할 때 사용한다. col 대신 row를 사용해도 된다. 여기에는 categorical(=범주형) 자료가 온다. (만약 값이 많으면..?) hue는 그래프에 표현되는 색상을 의미한다. style은 범주형 자료를 다르게 표현할 때 사용한다. (예: 동그라미, 별표 등) 대개 범주형 데이터를 지정한다. size 자료의 크기를 의미한다. 3. Grouped barplots123456789101112131415import seaborn as snssns.set_theme(style=&quot;whitegrid&quot;) # 축의 색상# 온라인 저장소에서 예제 데이터 세트를 로드한다.penguins = sns.load_dataset(&quot;penguins&quot;)# Draw a nested barplot by species and sexg = sns.catplot( data=penguins, kind=&quot;bar&quot;, x=&quot;species&quot;, y=&quot;body_mass_g&quot;, hue=&quot;sex&quot;, ci=&quot;sd&quot;, palette=&quot;dark&quot;, alpha=.6, height=6)g.despine(left=True)g.set_axis_labels(&quot;&quot;, &quot;Body mass (g)&quot;)g.legend.set_title(&quot;&quot;) 소스코드에 대한 설명을 간단히 하면 아래와 같다. seaborn.catplot: 하나의 수치형 변수와 하나 이상의 범주형 변수 간의 관계를 보여주는 그래프 kind: 그릴 플롯의 종류는 범주 형 좌표축 수준 플로팅 함수의 이름에 해당합니다. x, y, hue: 긴 형식의 데이터를 그리기위한 입력입니다. ci: 추정값 주위를 그리는 신뢰 구간의 크기입니다. “sd”인 경우 부트 스트랩을 건너 뛰고 관측 값의 표준 편차를 그립니다. palette: 다양한 수준의 hue변수 에 사용할 색상 입니다. alpha: ?? (그래프 투명도? 숫자가 작으면 연해진다.) height: 전체 플롯 세로 높이 (가로도 자동으로 조정된다?)","link":"/2020/11/02/study/kaggle_edu_Chapter_1_2_Python_visualisation_seaborn/"},{"title":"8장 기본 명령어","text":"8.1 SELECT테이블 전체를 검색하려면 *12SELECT *FROM TB_CUSTOMER; 필드가 많은 테이블에서 필요한 내용만 검색하려면 ,12345SELECT CUSTOMER_CD, CUSTOMER_NM, PHONE_NUMBER, EMAILFROM TB_CUSTOMER; 필드 제목을 한글로 바꾸려면 AS (생략가능)12345SELECT CUSTOMER_CD AS 고객코드, CUSTOMER_NM AS 고객명, PHONE_NUMBER AS 전화번호, EMAIL AS 이메일FROM TB_CUSTOMER; 수정한 게 안 올라간다","link":"/2020/11/02/study/sql_10minutes_ch08_basic_command_language/"},{"title":"캐글 타이타닉 분석","text":"사전 준비Kaggle 데이터 불러오기Kaggle API 설치1!pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9) Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1) Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1) Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;kaggle) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify-&gt;kaggle) (1.3) Kaggle Token 다운로드 아래 코드는 Kaggle API 토큰을 업로드 하는 코드이다. 12345678from google.colab import filesuploaded = files.upload()for fn in uploaded.keys(): print('uploaded file &quot;{name}&quot; with length {length} bytes'.format( name=fn, length=len(uploaded[fn]))) # kaggle.json을 아래 폴더로 옮긴 뒤, file을 사용할 수 있도록 권한을 부여한다. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json uploaded file &quot;kaggle.json&quot; with length 63 bytes 실제로 kaggle.json 파일이 업로드 되었는지 확인 1ls -1ha ~/.kaggle/kaggle.json /root/.kaggle/kaggle.json 구글 드라이브 연동123456789101112from google.colab import drive # 패키지 불러오기 from os.path import join # 구글 드라이브 마운트ROOT = &quot;/content/drive&quot; # 드라이브 기본 경로print(ROOT) # print content of ROOT (Optional)drive.mount(ROOT) # 드라이브 기본 경로 # 프로젝트 파일 생성 및 다운받을 경로 이동MY_GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/python_basic/kaggle_titanic/data'PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)print(PROJECT_PATH) /content/drive Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&quot;/content/drive&quot;, force_remount=True). /content/drive/My Drive/Colab Notebooks/python_basic/kaggle_titanic/data 1%cd &quot;{PROJECT_PATH}&quot; /content/drive/My Drive/Colab Notebooks/python_basic/kaggle_titanic/data kaggle competition list 불러오기 캐글 대회 목록 불러오기 1!kaggle competitions list Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4) ref deadline category reward teamCount userHasEntered --------------------------------------------- ------------------- --------------- --------- --------- -------------- contradictory-my-dear-watson 2030-07-01 23:59:00 Getting Started Prizes 134 False gan-getting-started 2030-07-01 23:59:00 Getting Started Prizes 185 False tpu-getting-started 2030-06-03 23:59:00 Getting Started Knowledge 315 False digit-recognizer 2030-01-01 00:00:00 Getting Started Knowledge 2356 False titanic 2030-01-01 00:00:00 Getting Started Knowledge 18089 True house-prices-advanced-regression-techniques 2030-01-01 00:00:00 Getting Started Knowledge 4541 True connectx 2030-01-01 00:00:00 Getting Started Knowledge 391 False nlp-getting-started 2030-01-01 00:00:00 Getting Started Knowledge 1184 False rock-paper-scissors 2021-02-01 23:59:00 Playground Prizes 158 False riiid-test-answer-prediction 2021-01-07 23:59:00 Featured $100,000 1470 False nfl-big-data-bowl-2021 2021-01-05 23:59:00 Analytics $100,000 0 False competitive-data-science-predict-future-sales 2020-12-31 23:59:00 Playground Kudos 9344 False halite-iv-playground-edition 2020-12-31 23:59:00 Playground Knowledge 43 False predict-volcanic-eruptions-ingv-oe 2020-12-28 23:59:00 Playground Swag 193 False hashcode-drone-delivery 2020-12-14 23:59:00 Playground Knowledge 79 False cdp-unlocking-climate-solutions 2020-12-02 23:59:00 Analytics $91,000 0 False lish-moa 2020-11-30 23:59:00 Research $30,000 3400 False google-football 2020-11-30 23:59:00 Featured $6,000 917 False conways-reverse-game-of-life-2020 2020-11-30 23:59:00 Playground Swag 131 False lyft-motion-prediction-autonomous-vehicles 2020-11-25 23:59:00 Featured $30,000 780 False Titanic: Machine Learning from Disaster 데이터셋 불러오기 타이타닉 대회 데이터를 가져오는 코드이다. 1!kaggle competitions download -c titanic Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4) Downloading gender_submission.csv to /content/drive/My Drive/Colab Notebooks/python_basic/kaggle_titanic/data 0% 0.00/3.18k [00:00&lt;?, ?B/s] 100% 3.18k/3.18k [00:00&lt;00:00, 426kB/s] Downloading train.csv to /content/drive/My Drive/Colab Notebooks/python_basic/kaggle_titanic/data 0% 0.00/59.8k [00:00&lt;?, ?B/s] 100% 59.8k/59.8k [00:00&lt;00:00, 8.45MB/s] Downloading test.csv to /content/drive/My Drive/Colab Notebooks/python_basic/kaggle_titanic/data 0% 0.00/28.0k [00:00&lt;?, ?B/s] 100% 28.0k/28.0k [00:00&lt;00:00, 3.99MB/s] 리눅스 명령어 ls는 경로(폴더) 내 모든 데이터 파일을 보여준다. 1!ls gender_submission.csv test.csv train.csv 캐글 데이터 수집 및 EDA우선 데이터를 수집하기에 앞서서 EDA에 관한 필수 패키지를 설치하자. 12345678import pandas as pd # 데이터 가공, 변환(dplyr)import pandas_profiling # 보고서 기능 # 아나콘다 할 때... 실습import numpy as np # 수치 연산 &amp; 배열, 행렬import matplotlib as mpl # 시각화import matplotlib.pyplot as plt # 시각화import seaborn as sns # 시각화from IPython.core.display import display, HTML 데이터 수집여기에서는 우선 test.csv &amp; train.csv 파일을 받도록 한다. 1234# 경로 변경 (프로젝트 파일 생성 및 다운받을 경로 이동)MY_GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/python_basic/kaggle_titanic'PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)print(PROJECT_PATH) /content/drive/My Drive/Colab Notebooks/python_basic/kaggle_titanic 1%cd &quot;{PROJECT_PATH}&quot; /content/drive/My Drive/Colab Notebooks/python_basic/kaggle_titanic 1!ls data source 123train = pd.read_csv('data/train.csv')test = pd.read_csv('data/test.csv')print(&quot;data import is done&quot;) data import is done 데이터 확인 Kaggle 데이터를 불러오면 우선 확인해야 하는 것은 데이터셋의 크기다. 변수의 갯수 수치형 변수 &amp; 범주형 변수의 개수 등을 파악해야 한다. Point 1 - train데이터에서 굳이 훈련데이터와 테스트 데이터를 구분할 필요는 없다. 보통 Kaggle에서는 테스트 데이터를 주기적으로 업데이트 해준다. Point 2 - 보통 test 데이터의 변수의 개수가 하나 더 작다. 1train.shape, test.shape ((891, 12), (418, 11)) 그 후 train데이터의 상위 5개의 데이터만 확인한다. 1display(train.head()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 그 다음 확인해야 하는 것은 수치형 변수와 범주형 변수를 구분한다. 먼저 numerical_features를 구분하자. 데이터의 변수가 많아서, 일단 숫자형과 문자형으로 분리한 후, EDA를 하려고 한다. 아래 코드는 train데이터에서 숫자형 변수만 추출하는 코드이다. 123numeric_features = train.select_dtypes(include=[np.number]) # 수치형 데이터print(numeric_features.columns)print(&quot;The total number of include numeric features are: &quot;, len(numeric_features.columns)) Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object') The total number of include numeric features are: 7 numeric_features을 제외한 나머지 변수를 추출하자. (Categorical 등) 123categorical_features = train.select_dtypes(exclude=[np.number]) # 수치형이 아닌 데이터print(categorical_features.columns)print(&quot;The total number of exclude numeric features are: &quot;, len(categorical_features.columns)) Index(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], dtype='object') The total number of exclude numeric features are: 5 우선 전체 데이터는 891개 변수는 12개로 확인했다. 그 중 수치형 변수는 7개, 문자형 변수는 5개인 것으로 확인된다. 타이타닉 분석 따라하기 colab, 전태균님의 타이타닉 분석 타이타닉에 탑승한 사람들의 신상정보를 활용하여, 승선한 사람들의 생존여부를 예측하는 모델을 생성할 것이다. 12345678910111213141516import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns# matplotlib 의 기본 scheme 말고 seaborn scheme 을 세팅하고,# 일일이 graph 의 font size 를 지정할 필요 없이 seaborn 의 font_scale 을 사용하면 편하다.plt.style.use('seaborn')sns.set(font_scale = 2.1)import missingno as msno# warnings 무시import warningswarnings.filterwarnings('ignore')%matplotlib inline 데이터셋 확인 대부분의 캐글 데이터들은 장 정제되어 있다. 하지만 가끔 null data가 존재한다. 이를 확인하고, 향후 수정한다. pandas는 파이썬에서 테이블화 된 데이터를 다루는 데 가장 최적화되어 있으며, 많이 쓰이는 라이브러리이다. pandas를 사용하여 Dataset의 간단한 통계적 분석부터, 복잡한 처리들을 간단한 메소드를 사용하여 해낼 수 있다. pandas는 파이썬으로 데이터 분석을 한다고 하면 능숙해져야 할 라이브러리이다. 1!ls() /bin/bash: -c: line 1: syntax error: unexpected end of file 123df_train = traindf_test = testdf_train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 이 타이타닉에서 Feature는 Pclass(티켓의 클래스), Age(성별), SibSp(함께 탑승한 형제와 배우자의 수), Parch(함께 탑승한 부모, 아이의 수), Fare(탑승료) 이며, 예측하려는 target label은 Survived(생존여부) 이다. 변수(feature, variable) 정의 설명 타입 Survived 생존여부 target label 임. 1, 0 으로 표현됨 integer Pclass 티켓의 클래스 1 = 1st, 2 = 2nd, 3 = 3rd 클래스로 나뉘며 categorical feature integer Sex 성별 male, female 로 구분되며 binary string Age 나이 continuous integer SibSp 함께 탑승한 형제와 배우자의 수 quantitative integer Parch 함께 탑승한 부모, 아이의 수 quantitative integer Ticket 티켓 번호 alphabat + integer string Fare 탑승료 continuous float Cabin 객실 번호 alphabat + integer string Embarked 탑승 항구 C = Cherbourg, Q = Queenstown, S = Southampton string Feature Engineering은 머신러닝 알고리즘을 작동하기 위해 데이터에 대한 도메인 지식을 활용하여 특징(Feature)을 만들어내는 과정이다. 출처 또는 머신러닝 모델을 위한 데이터 테이블의 컬럼(특징)을 생성하거나 선택하는 작업을 의미한다. 간단히 정리하면, 모델의 성능을 높이기 위해, 모델에 입력할 데이터를 만들기 위해 주어진 초기 데이터로부터 특징을 가공하고 생성하는 전체 과정을 의미한다. Null data checkdescribe() 메소드를 쓰면 각 feature가 가진 통계치들을 반환해준다. 1df_train.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Age SibSp Parch Fare count 891.000000 891.000000 891.000000 714.000000 891.000000 891.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 0.381594 32.204208 std 257.353842 0.486592 0.836071 14.526497 1.102743 0.806057 49.693429 min 1.000000 0.000000 1.000000 0.420000 0.000000 0.000000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 0.000000 7.910400 50% 446.000000 0.000000 3.000000 28.000000 0.000000 0.000000 14.454200 75% 668.500000 1.000000 3.000000 38.000000 1.000000 0.000000 31.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 6.000000 512.329200 1df_test.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Pclass Age SibSp Parch Fare count 418.000000 418.000000 332.000000 418.000000 418.000000 417.000000 mean 1100.500000 2.265550 30.272590 0.447368 0.392344 35.627188 std 120.810458 0.841838 14.181209 0.896760 0.981429 55.907576 min 892.000000 1.000000 0.170000 0.000000 0.000000 0.000000 25% 996.250000 1.000000 21.000000 0.000000 0.000000 7.895800 50% 1100.500000 3.000000 27.000000 0.000000 0.000000 14.454200 75% 1204.750000 3.000000 39.000000 1.000000 0.000000 31.500000 max 1309.000000 3.000000 76.000000 8.000000 9.000000 512.329200 이 테이블을 보면 PassengerId 숫자와 다른, null data가 존재하는 열(feature)이 있는 것 같다고 하는데 공부가 필요하다. 이를 좀 더 보기 편하도록 그래프로 시각화해서 살펴본다. 123for col in df_train.columns: msg = 'column: {:&gt;10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum() / df_train[col].shape[0])) print(msg) column: PassengerId Percent of NaN value: 0.00% column: Survived Percent of NaN value: 0.00% column: Pclass Percent of NaN value: 0.00% column: Name Percent of NaN value: 0.00% column: Sex Percent of NaN value: 0.00% column: Age Percent of NaN value: 19.87% column: SibSp Percent of NaN value: 0.00% column: Parch Percent of NaN value: 0.00% column: Ticket Percent of NaN value: 0.00% column: Fare Percent of NaN value: 0.00% column: Cabin Percent of NaN value: 77.10% column: Embarked Percent of NaN value: 0.22% 123for col in df_test.columns: msg = 'column: {:&gt;10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum() / df_test[col].shape[0])) print(msg) column: PassengerId Percent of NaN value: 0.00% column: Pclass Percent of NaN value: 0.00% column: Name Percent of NaN value: 0.00% column: Sex Percent of NaN value: 0.00% column: Age Percent of NaN value: 20.57% column: SibSp Percent of NaN value: 0.00% column: Parch Percent of NaN value: 0.00% column: Ticket Percent of NaN value: 0.00% column: Fare Percent of NaN value: 0.24% column: Cabin Percent of NaN value: 78.23% column: Embarked Percent of NaN value: 0.00% Train, Test 데이터셋에서 Age(둘 다 약 20%), Cabin(둘 다 약 80%), Embarked(Train만 0.22%) null data가 존재하는 것을 볼 수 있다. missingno(MSNO)라는 라이브러리를 사용하면 null data의 존재를 더 쉽게 볼 수 있다. 1msno.matrix(df = df_train.iloc[:, :], figsize = (8, 8), color = (0.8, 0.5, 0.2)) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f6a1b8e4ef0&gt; 1msno.bar(df = df_train.iloc[:, :], figsize = (8, 8), color = (0.8, 0.5, 0.2)) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f6a1b94d160&gt; 1msno.bar(df = df_test.iloc[:, :], figsize = (8, 8), color = (0.8, 0.5, 0.2)) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f6a1baef198&gt; Target label 확인 target label이 어떤 분포(distribution)를 가지고 있는 지 확인해봐야 한다. binary classification 문제의 경우에서, 1과 0의 분포가 어떠냐에 따라 모델의 평가 방법이 달라질 수 있다. 123456789f, ax = plt.subplots(1, 2, figsize = (18, 8))df_train['Survived'].value_counts().plot.pie(explode = [0, 0.1], autopct = '%1.1f%%', ax = ax[0], shadow = True)ax[0].set_title('Pie plot - Survived')ax[0].set_ylabel('')sns.countplot('Survived', data = df_train, ax = ax[1])ax[1].set_title('Count plot - Survived')plt.show() 38.4%가 살아남았다는 걸 알 수 있다. target label의 분포가 제법 균일(balanced)하다. 불균일한 경우, 예를 들어 100 중 1이 99, 0이 1개인 경우에는 만약 모델이 모든 것을 1이라 해도 정확도가 99%가 나오게 된다. 0을 찾는 문제라면 이 모델은 원하는 결과를 줄 수 없게 된다. EDA 탐색적 데이터 분석 Exploratory Data Analysis. 많은 데이터 안의 숨겨진 사실을 찾기 위해서는 적절한 시각화가 필요하다. 시각화 라이브러리는 matplotlib, seaborn, plotly 등이 있다. 특정 목적에 맞는 소스코드를 정리해서 필요할 때마다 참고하면 편하다. Pclass Pclass는 서수형 데이터(ordinal)이다. 카테고리이면서, 순서가 있는 데이터 타입이다. Pclass에 따른 생존률의 차이를 살펴보겠다. 엑셀의 피벗 차트와 유사한 작업을 하게 되는데, pandas dataframe엣는 groupby를 사용하면 쉽게 할 수 있다. 또한 pivot이라는 메소드도 있다. ‘Pclass’, “Survived’를 가져온 후, Pclass로 묶는다. 그러고 나면 각 Pclass마다 0과 1이 count가 되는데, 이를 평균 내면 각 Pclass별 생존률이 나온다. 아래와 같이 count()를 하면, 각 Pclass에 몇 명이 있는 지 확인할 수 있다. 1df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = True).count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass 1 216 2 184 3 491 아래와 같이 sum()을 하면, 216명 중 생존한(Survived = 1) 사람의 총합을 주게 된다. 1df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = True).sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived Pclass 1 136 2 87 3 119 pandas의 crosstab을 사용하면 위 과정을 좀 더 수월하게 볼 수 있다. 1pd.crosstab(df_train['Pclass'], df_train['Survived'], margins = True).style.background_gradient(cmap = 'summer_r') #T_cc711248_1e5c_11eb_8373_0242ac1c0002row0_col0,#T_cc711248_1e5c_11eb_8373_0242ac1c0002row1_col1,#T_cc711248_1e5c_11eb_8373_0242ac1c0002row1_col2{ background-color: #ffff66; color: #000000; }#T_cc711248_1e5c_11eb_8373_0242ac1c0002row0_col1{ background-color: #cee666; color: #000000; }#T_cc711248_1e5c_11eb_8373_0242ac1c0002row0_col2{ background-color: #f4fa66; color: #000000; }#T_cc711248_1e5c_11eb_8373_0242ac1c0002row1_col0{ background-color: #f6fa66; color: #000000; }#T_cc711248_1e5c_11eb_8373_0242ac1c0002row2_col0{ background-color: #60b066; color: #000000; }#T_cc711248_1e5c_11eb_8373_0242ac1c0002row2_col1{ background-color: #dfef66; color: #000000; }#T_cc711248_1e5c_11eb_8373_0242ac1c0002row2_col2{ background-color: #90c866; color: #000000; }#T_cc711248_1e5c_11eb_8373_0242ac1c0002row3_col0,#T_cc711248_1e5c_11eb_8373_0242ac1c0002row3_col1,#T_cc711248_1e5c_11eb_8373_0242ac1c0002row3_col2{ background-color: #008066; color: #f1f1f1; } Survived 0 1 All Pclass &lt;tr&gt; &lt;th id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002level0_row0&quot; class=&quot;row_heading level0 row0&quot; &gt;1&lt;/th&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row0_col0&quot; class=&quot;data row0 col0&quot; &gt;80&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row0_col1&quot; class=&quot;data row0 col1&quot; &gt;136&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row0_col2&quot; class=&quot;data row0 col2&quot; &gt;216&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002level0_row1&quot; class=&quot;row_heading level0 row1&quot; &gt;2&lt;/th&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row1_col0&quot; class=&quot;data row1 col0&quot; &gt;97&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row1_col1&quot; class=&quot;data row1 col1&quot; &gt;87&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row1_col2&quot; class=&quot;data row1 col2&quot; &gt;184&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002level0_row2&quot; class=&quot;row_heading level0 row2&quot; &gt;3&lt;/th&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row2_col0&quot; class=&quot;data row2 col0&quot; &gt;372&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row2_col1&quot; class=&quot;data row2 col1&quot; &gt;119&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row2_col2&quot; class=&quot;data row2 col2&quot; &gt;491&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002level0_row3&quot; class=&quot;row_heading level0 row3&quot; &gt;All&lt;/th&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row3_col0&quot; class=&quot;data row3 col0&quot; &gt;549&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row3_col1&quot; class=&quot;data row3 col1&quot; &gt;342&lt;/td&gt; &lt;td id=&quot;T_cc711248_1e5c_11eb_8373_0242ac1c0002row3_col2&quot; class=&quot;data row3 col2&quot; &gt;891&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 그룹화된 객체에 mean()을 하게 되면, 각 클래스별 생존률을 얻을 수 있다. class 1이면 아래와 같다. $$ {80 \\over (80 + 136)} \\approx 0.63 $$ 1df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = True).mean().sort_values(by = 'Survived', ascending = False).plot.bar() &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f6a1bab4828&gt; Pclass가 좋을 수록(1st) 생존률이 높은 것을 확인할 수 있다. seaborn의 countplot을 이용하면 특정 label에 따른 개수를 확인해볼 수 있다. 12345678y_position = 1.02f, ax = plt.subplots(1, 2, figsize = (18, 8))df_train['Pclass'].value_counts().plot.bar(color = ['#CD7F32','#FFDF00','#D3D3D3'], ax = ax[0])ax[0].set_title('Number of Passengers By Pclass', y = y_position)ax[0].set_ylabel('Count')sns.countplot('Pclass', hue = 'Survived', data = df_train, ax = ax[1])ax[1].set_title('Pclass: Survived vs Dead', y = y_position)plt.show() Pclass가 높을 수록, 생존 확률이 높은 걸 확인할 수 있다? Pclass 1, 2, 3 순서대로 63%, 48%, 25% 이다. 생존에 Pclass가 큰 영향을 미친다고 생각해볼 수 있으며, 나중에 모델을 세울 때 이 feature를 사용하는 것이 좋을 것이라 판단할 수 있다. Sex 성별로 생존률이 어떻게 달라지는 지 확인해보겠다. 마찬가지로 pandas groupby와 seaborn countplot을 사용해서 시각화해본다. 123456f, ax = plt.subplots(1, 2, figsize = (18, 8))df_train[['Sex', 'Survived']].groupby(['Sex'], as_index = True).mean().plot.bar(ax = ax[0])ax[0].set_title('Survived vs Sex')sns.countplot('Sex', hue = 'Survived', data = df_train, ax = ax[1])ax[1].set_title('Sex: Survived vs Dead')plt.show() 여자가 생존할 확률이 높은 걸 확인할 수 있다. 1df_train[['Sex', &quot;Survived&quot;]].groupby(['Sex'], as_index = False).mean().sort_values(by = &quot;Survived&quot;, ascending = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex Survived 0 female 0.742038 1 male 0.188908 1pd.crosstab(df_train['Sex'], df_train['Survived'], margins = True).style.background_gradient(cmap = 'summer_r') #T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row0_col0,#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row0_col2,#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row1_col1{ background-color: #ffff66; color: #000000; }#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row0_col1{ background-color: #77bb66; color: #000000; }#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row1_col0{ background-color: #2c9666; color: #000000; }#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row1_col2{ background-color: #8bc566; color: #000000; }#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row2_col0,#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row2_col1,#T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row2_col2{ background-color: #008066; color: #f1f1f1; } Survived 0 1 All Sex &lt;tr&gt; &lt;th id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002level0_row0&quot; class=&quot;row_heading level0 row0&quot; &gt;female&lt;/th&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row0_col0&quot; class=&quot;data row0 col0&quot; &gt;81&lt;/td&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row0_col1&quot; class=&quot;data row0 col1&quot; &gt;233&lt;/td&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row0_col2&quot; class=&quot;data row0 col2&quot; &gt;314&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002level0_row1&quot; class=&quot;row_heading level0 row1&quot; &gt;male&lt;/th&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row1_col0&quot; class=&quot;data row1 col0&quot; &gt;468&lt;/td&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row1_col1&quot; class=&quot;data row1 col1&quot; &gt;109&lt;/td&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row1_col2&quot; class=&quot;data row1 col2&quot; &gt;577&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002level0_row2&quot; class=&quot;row_heading level0 row2&quot; &gt;All&lt;/th&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row2_col0&quot; class=&quot;data row2 col0&quot; &gt;549&lt;/td&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row2_col1&quot; class=&quot;data row2 col1&quot; &gt;342&lt;/td&gt; &lt;td id=&quot;T_6e4079ea_1e5f_11eb_8373_0242ac1c0002row2_col2&quot; class=&quot;data row2 col2&quot; &gt;891&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; $$ {81 \\over (81 + 233)} \\approx 0.74 $$ Pclass와 마찬가지로, Sex도 예측 모델에 쓰일 중요한 feature 임을 알 수 있다. Both Sex and Pclass Sex, Pclass 2가지에 관하여 생존이 어떻게 달라지는 지 확인해 본다. seaborn의 factorplot을 이용하면, 손쉽게 3개의 차원으로 이루어진 그래프를 그릴 수 있다. 12sns.factorplot('Pclass', 'Survived', hue = 'Sex', data = df_train, size = 6, aspect = 1.5) &lt;seaborn.axisgrid.FacetGrid at 0x7f6a1ae2a7b8&gt; 모든 클래스에서 여자가 살 확률이 남자보다 높은 걸 알 수 있다. 또한 남자, 여자 상관없이 클래스가 높을 수록 살 확률이 높다. hue = ‘Sex’ 대신 col = ‘Pclass’로 하면 아래와 같아진다. (column) 123sns.factorplot(x = 'Sex', y = &quot;Survived&quot;, col = 'Pclass', data = df_train, satureation = 5, size = 9, aspect = 1) &lt;seaborn.axisgrid.FacetGrid at 0x7f6a1ae10b70&gt; Age Age Feature를 살펴보자. 123print('제일 나이 많은 탑승객 : {:.1f} Years'.format(df_train['Age'].max()))print('제일 어린 탑승객 : {:.1f} Years'.format(df_train['Age'].min()))print('탑승객 평균 나이 : {:.1f} Years'.format(df_train['Age'].mean())) 제일 나이 많은 탑승객 : 80.0 Years 제일 어린 탑승객 : 0.4 Years 탑승객 평균 나이 : 29.7 Years 생존에 따른 Age의 히스토그램을 그려보겠다. 12345fig, ax = plt.subplots(1, 1, figsize = (9, 5))sns.kdeplot(df_train[df_train['Survived'] == 1]['Age'], ax = ax)sns.kdeplot(df_train[df_train['Survived'] == 0]['Age'], ax = ax)plt.legend(['Survived == 1', 'Survived == 0'])plt.show() 생존자 중 나이가 어린 경우가 많음을 볼 수 있다. 123456789# Age distribution withing classesplt.figure(figsize = (8, 6))df_train['Age'][df_train['Pclass'] == 1].plot(kind = 'kde')df_train['Age'][df_train['Pclass'] == 2].plot(kind = 'kde')df_train['Age'][df_train['Pclass'] == 3].plot(kind = 'kde')plt.xlabel('Age')plt.title('Age Distribution within classes')plt.legend(['1st Class', '2nd Class', '3rd Class']) &lt;matplotlib.legend.Legend at 0x7f6a1bcc4710&gt; Pclass가 높을 수록 나이 많은 사람의 비중이 커진다. 나이대가 변하면서 생존률이 어떻게 되는 지 보려고 한다. 나이 범위를 점점 넓혀가며, 생존률이 어떻게 되는 지 한 번 보자. 12345678910cummulate_survival_ratio = []for i in range(1, 80): cummulate_survival_ratio.append(df_train[df_train['Age'] &lt; i]['Survived'].sum() / len(df_train[df_train['Age'] &lt; i]['Survived']))plt.figure(figsize = (7, 7))plt.plot(cummulate_survival_ratio)plt.title('Survival rate change depending on range of Age', y = 1.02)plt.ylabel('Survival rate')plt.xlabel('Range of Age(0~x)')plt.show() 나이가 어릴 수록 생존률이 확실히 높은 것을 확인할 수 있다. Age는 중요한 Feature로 쓰일 수 있음을 확인했다. Pclass, Sex, Age Sex, Pclass, Age, Sruvived 모두에 대해서 보고 싶다면, 이를 쉽게 그려주는 seaborn의 biolinplot을 사용한다. x축은 우리가 나눠서 보고 싶어하는 case(Pclass, Sex)를 나타내고, y축은 보고 싶어하는 distribution(Age)이다. 123f, ax = plt.subplots(1, 2, figsize = (18,8))sns.violinplot(&quot;Pclass&quot;, &quot;Age&quot;, hue = &quot;Survived&quot;, data = df_train, scale = 'count', split = True, ax = ax[0])","link":"/2020/11/04/study/kaggle_titanic/"},{"title":"판다스 10분 완성","text":"판다스 10분 완성데잇걸즈210 minutes to pandasPandas Cheat SheetCookbook 123import pandas as pdimport numpy as npimport matplotlib.pyplot as plt 1) 객체 생성 (Object Creation)데이터 구조 소개 섹션 (Intro to data structures) pandas.Series()값을 가지고 있는 리스트를 통해 Series를 만들고, 정수로 만들어진 인덱스를 기본값으로 불러온다. 12s = pd.Series([1,3,5,np.nan,6,8])s 0 1.0 1 3.0 2 5.0 3 NaN 4 6.0 5 8.0 dtype: float64 pandas.date_range()DatetimeIndex 데이터프레임을 만든다. 12dates = pd.date_range('20130101', periods=6)dates DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D') pandas.DataFrame()레이블이 있는 열을 가지고 있는 numpy 배열을 전달하여 데이터프레임을 만든다. 12df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 0.682032 -1.905166 -0.545421 0.238074 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 2013-01-04 0.509850 0.801045 0.015410 -0.671559 2013-01-05 1.403769 1.191673 -1.332947 0.663252 2013-01-06 0.825406 1.283820 0.421918 -0.115307 Series와 같은 것으로 변환될 수 있는 객체들의 딕셔너리로 구성된 데이터프레임을 만든다. 1234567df2 = pd.DataFrame({'A' : 1., 'B' : pd.Timestamp('20130102'), 'C' : pd.Series(1,index=list(range(4)),dtype='float32'), 'D' : np.array([3] * 4,dtype='int32'), 'E' : pd.Categorical([&quot;test&quot;,&quot;train&quot;,&quot;test&quot;,&quot;train&quot;]), 'F' : 'foo' })df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E F 0 1.0 2013-01-02 1.0 3 test foo 1 1.0 2013-01-02 1.0 3 train foo 2 1.0 2013-01-02 1.0 3 test foo 3 1.0 2013-01-02 1.0 3 train foo .dtypes데이터프레임 결과물의 열은 다양한 데이터 타입으로 구성된다. 1df2.dtypes A float64 B datetime64[ns] C float32 D int32 E category F object dtype: object 2) 데이터 확인하기 (Viewing Data)Basic Section (Essential basic functionality) .head(), .tail()괄호() 안에 숫자가 들어간다면 처음/마지막 줄의 특정 줄을 불러올 수 있다. 숫자가 들어가지 않으면 기본값인 5줄로 처리된다. 1df.head() # 시작에서 처음 5줄 불러온다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 0.682032 -1.905166 -0.545421 0.238074 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 2013-01-04 0.509850 0.801045 0.015410 -0.671559 2013-01-05 1.403769 1.191673 -1.332947 0.663252 1df.tail(3) # 끝에서 마지막 3줄을 불러온다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-04 0.509850 0.801045 0.015410 -0.671559 2013-01-05 1.403769 1.191673 -1.332947 0.663252 2013-01-06 0.825406 1.283820 0.421918 -0.115307 .index, .columns, .values인덱스, 열 그리고 numpy 데이터에 대한 세부 정보를 본다. 1df.index DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D') 1df.columns Index(['A', 'B', 'C', 'D'], dtype='object') 1df.values array([[ 0.68203244, -1.90516572, -0.54542119, 0.23807417], [ 0.12077523, -0.57233779, -2.02072777, -0.5424847 ], [-0.57519992, -0.44213025, -0.15472648, -1.43383629], [ 0.5098502 , 0.8010451 , 0.01541041, -0.67155854], [ 1.40376854, 1.1916732 , -1.33294702, 0.66325193], [ 0.82540573, 1.28382005, 0.42191767, -0.11530747]]) .describe()describe()는 데이터의 대략적인 통계적 정보 요약을 보여준다. 1df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D count 6.000000 6.000000 6.000000 6.000000 mean 0.494439 0.059484 -0.602749 -0.310310 std 0.671655 1.252312 0.914322 0.739363 min -0.575200 -1.905166 -2.020728 -1.433836 25% 0.218044 -0.539786 -1.136066 -0.639290 50% 0.595941 0.179457 -0.350074 -0.328896 75% 0.789562 1.094016 -0.027124 0.149729 max 1.403769 1.283820 0.421918 0.663252 .T데이터를 전치한다.전치 행렬은 행과 열을 교환하여 얻는 행렬이다. 주대각선을 축으로 하는 반사 대칭을 가하여 얻는 행렬이다. 1df.T .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 2013-01-01 2013-01-02 2013-01-03 2013-01-04 2013-01-05 2013-01-06 A 0.682032 0.120775 -0.575200 0.509850 1.403769 0.825406 B -1.905166 -0.572338 -0.442130 0.801045 1.191673 1.283820 C -0.545421 -2.020728 -0.154726 0.015410 -1.332947 0.421918 D 0.238074 -0.542485 -1.433836 -0.671559 0.663252 -0.115307 .sort_index()축 별로 정렬한다. 1df.sort_index(axis=1, ascending=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } D C B A 2013-01-01 0.238074 -0.545421 -1.905166 0.682032 2013-01-02 -0.542485 -2.020728 -0.572338 0.120775 2013-01-03 -1.433836 -0.154726 -0.442130 -0.575200 2013-01-04 -0.671559 0.015410 0.801045 0.509850 2013-01-05 0.663252 -1.332947 1.191673 1.403769 2013-01-06 -0.115307 0.421918 1.283820 0.825406 .sort_values()값 별로 정렬한다. 1df.sort_values(by='B') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 0.682032 -1.905166 -0.545421 0.238074 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 2013-01-04 0.509850 0.801045 0.015410 -0.671559 2013-01-05 1.403769 1.191673 -1.332947 0.663252 2013-01-06 0.825406 1.283820 0.421918 -0.115307 3) 선택 (Selection)데이터 인덱싱 및 선택 문서 (Indexing and selecting data)다중 인덱싱 / 심화 인덱싱 (MultiIndex / advanced indexing) 3-1) 데이터 얻기 (Getting)df.A 와 동일한 Series를 생성하는 단일 열을 선택한다. 1df['A'] 2013-01-01 0.682032 2013-01-02 0.120775 2013-01-03 -0.575200 2013-01-04 0.509850 2013-01-05 1.403769 2013-01-06 0.825406 Freq: D, Name: A, dtype: float64 행을 분할하는 [ ]를 통해 선택한다. 1df[0:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 0.682032 -1.905166 -0.545421 0.238074 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 1df['20130102':'20130104'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 2013-01-04 0.509850 0.801045 0.015410 -0.671559 3-2) Label 을 통한 선택 (Selection by Label)Label을 통한 선택 (Indexing and selecting data)라벨을 사용하여 횡단면을 얻는다. 1df.loc[dates[0]] # 2013-01-01 가로 데이터 A 0.682032 B -1.905166 C -0.545421 D 0.238074 Name: 2013-01-01 00:00:00, dtype: float64 라벨을 사용하여 여러 축(의 데이터)을 얻는다. 1df.loc[:,['A','B']] # 맨 처음 &quot;:&quot;는 인덱스 범위인 것 같은데 아무것도 안 적으면 모든 데이터를 말하는 것 같다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2013-01-01 0.682032 -1.905166 2013-01-02 0.120775 -0.572338 2013-01-03 -0.575200 -0.442130 2013-01-04 0.509850 0.801045 2013-01-05 1.403769 1.191673 2013-01-06 0.825406 1.283820 양쪽 종단점을 포함한 라벨 슬라이싱을 본다. 1df.loc['20130102':'20130104', ['A','B']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2013-01-02 0.120775 -0.572338 2013-01-03 -0.575200 -0.442130 2013-01-04 0.509850 0.801045 반환되는 객체의 차원를 줄인다. 1df.loc['20130102',['A','B']] A 0.120775 B -0.572338 Name: 2013-01-02 00:00:00, dtype: float64 스칼라 값을 얻는다.스칼라란 선형대수학에서 선형공간을 정의 할 때, 선형공간의 원소와 스칼라 곱을 하는 체의 원소이다. 1df.loc[dates[0],'A'] 0.6820324363584261 스칼라 값을 더 빠르게 구하는 방법이다. 1df.at[dates[0],'A'] 0.6820324363584261 3-3) 위치로 선택하기 (Selection by Position)위치로 선택하기 (Indexing and selecting data)넘겨받은 정수의 위치를 기준으로 선택한다. 1df.iloc[3] # 2013-01-04 데이터 A 0.509850 B 0.801045 C 0.015410 D -0.671559 Name: 2013-01-04 00:00:00, dtype: float64 정수로 표기된 슬라이스들을 통해, numpy / python과 유사하게 작동한다. 1df.iloc[3:5,0:2] # 3:5 -&gt; 3 이상 5 미만? .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2013-01-04 0.509850 0.801045 2013-01-05 1.403769 1.191673 정수로 표기된 위치값의 리스트들을 통해, numpy / python의 스타일과 유사해진다. 1df.iloc[[1,2,4],[0,2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A C 2013-01-02 0.120775 -2.020728 2013-01-03 -0.575200 -0.154726 2013-01-05 1.403769 -1.332947 명시적으로 행을 나누고자 하는 경우이다. 1df.iloc[1:3,:] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 명시적으로 열을 나누고자 하는 경우이다. 1df.iloc[:,1:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } B C 2013-01-01 -1.905166 -0.545421 2013-01-02 -0.572338 -2.020728 2013-01-03 -0.442130 -0.154726 2013-01-04 0.801045 0.015410 2013-01-05 1.191673 -1.332947 2013-01-06 1.283820 0.421918 명시적으로 (특정한) 값을 얻고자 하는 경우이다. 1df.iloc[1,1] # 2013-01-02의 B 데이터 -0.5723377908969021 스칼라 값을 빠르게 얻는 방법이다. 1df.iat[1,1] -0.5723377908969021 3-4) Boolean Indexing데이터를 선택하기 위해 단일 열의 값을 사용한다. 1df[df.A &gt; 0] # A값 음수인 2013-01-03 데이터 빠진다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 0.682032 -1.905166 -0.545421 0.238074 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 2013-01-04 0.509850 0.801045 0.015410 -0.671559 2013-01-05 1.403769 1.191673 -1.332947 0.663252 2013-01-06 0.825406 1.283820 0.421918 -0.115307 Boolean 조건을 충족하는 데이터프레임에서 값을 선택한다. 1df[df &gt; 0] # 음수는 NaN 처리된다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2013-01-01 0.682032 NaN NaN 0.238074 2013-01-02 0.120775 NaN NaN NaN 2013-01-03 NaN NaN NaN NaN 2013-01-04 0.509850 0.801045 0.015410 NaN 2013-01-05 1.403769 1.191673 NaN 0.663252 2013-01-06 0.825406 1.283820 0.421918 NaN 필터링을 위한 메소드 isin()을 사용한다. 123df2 = df.copy()df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 2013-01-01 0.682032 -1.905166 -0.545421 0.238074 one 2013-01-02 0.120775 -0.572338 -2.020728 -0.542485 one 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 two 2013-01-04 0.509850 0.801045 0.015410 -0.671559 three 2013-01-05 1.403769 1.191673 -1.332947 0.663252 four 2013-01-06 0.825406 1.283820 0.421918 -0.115307 three 1df2[df2['E'].isin(['two','four'])] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 2013-01-03 -0.575200 -0.442130 -0.154726 -1.433836 two 2013-01-05 1.403769 1.191673 -1.332947 0.663252 four 3-5) 설정 (Setting)새 열을 설정하면 데이터가 인덱스 별로 자동 정렬된다. 12s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))s1 2013-01-02 1 2013-01-03 2 2013-01-04 3 2013-01-05 4 2013-01-06 5 2013-01-07 6 Freq: D, dtype: int64 123456789101112df['F'] = s1# 라벨에 의해 값을 설정한다.df.at[dates[0],'A'] = 0# 위치에 의해 값을 설정한다.df.iat[0,1] = 0# Numpy 배열을 사용한 할당에 의해 값을 설정한다.df.loc[:,'D'] = np.array([5] * len(df))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 0.000000 0.000000 -0.545421 5 NaN 2013-01-02 0.120775 -0.572338 -2.020728 5 1.0 2013-01-03 -0.575200 -0.442130 -0.154726 5 2.0 2013-01-04 0.509850 0.801045 0.015410 5 3.0 2013-01-05 1.403769 1.191673 -1.332947 5 4.0 2013-01-06 0.825406 1.283820 0.421918 5 5.0 where 연산을 설정한다. 123df2 = df.copy()df2[df2 &gt; 0] = -df2df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 0.000000 0.000000 -0.545421 -5 NaN 2013-01-02 -0.120775 -0.572338 -2.020728 -5 -1.0 2013-01-03 -0.575200 -0.442130 -0.154726 -5 -2.0 2013-01-04 -0.509850 -0.801045 -0.015410 -5 -3.0 2013-01-05 -1.403769 -1.191673 -1.332947 -5 -4.0 2013-01-06 -0.825406 -1.283820 -0.421918 -5 -5.0 4) 결측치 (Missing Data)Missing data section (Working with missing data)Pandas는 결측치를 표현하기 위해 주로 np.nan 값을 사용한다.Reindexing으로 지정된 축 상의 인덱스를 변경/추가/삭제할 수 있다.Reindexing은 데이터의 복사본을 반환한다. 123df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])df1.loc[dates[0]:dates[1],'E'] = 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-01 0.000000 0.000000 -0.545421 5 NaN 1.0 2013-01-02 0.120775 -0.572338 -2.020728 5 1.0 1.0 2013-01-03 -0.575200 -0.442130 -0.154726 5 2.0 NaN 2013-01-04 0.509850 0.801045 0.015410 5 3.0 NaN 결측치를 가지고 있는 행들을 지운다. 1df1.dropna(how='any') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-02 0.120775 -0.572338 -2.020728 5 1.0 1.0 결측치를 채워 넣는다. 1df1.fillna(value=5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-01 0.000000 0.000000 -0.545421 5 5.0 1.0 2013-01-02 0.120775 -0.572338 -2.020728 5 1.0 1.0 2013-01-03 -0.575200 -0.442130 -0.154726 5 2.0 5.0 2013-01-04 0.509850 0.801045 0.015410 5 3.0 5.0 nan인 값에 boolean을 통한 표식을 얻는다.데이터프레임의 모든 값이 boolean 형태로 표시되도록 하며, nan인 값에만 True가 표시되게 하는 함수이다. 1pd.isna(df1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2013-01-01 False False False False True False 2013-01-02 False False False False False False 2013-01-03 False False False False False True 2013-01-04 False False False False False True 5) 연산 (Operation)이진 (Binary) 연산의 기본 섹션 (Flexible binary operations) 5-1) 통계 (Stats)12일반적으로 결측치를 제외한 후 연산된다.기술통계를 수행한다. 1df.mean() A 0.380767 B 0.377012 C -0.602749 D 5.000000 F 3.000000 dtype: float64 다른 축에서 동일한 연산을 수행한다. 1df.mean(1) 2013-01-01 1.113645 2013-01-02 0.705542 2013-01-03 1.165589 2013-01-04 1.865261 2013-01-05 2.052499 2013-01-06 2.506229 Freq: D, dtype: float64 정렬이 필요하며, 차원이 다른 객체로 연산해보겠다.pandas는 지정된 차원을 따라 자동으로 브로드 캐스팅된다.broadcast란 numpy에서 유래한 용어로, n차원이나 스칼라 값으로 연산을 수행할 때 도출되는 결과의 규칙을 설명하는 것을 의미합니다. 12s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)s 2013-01-01 NaN 2013-01-02 NaN 2013-01-03 1.0 2013-01-04 3.0 2013-01-05 5.0 2013-01-06 NaN Freq: D, dtype: float64 1df.sub(s, axis='index') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 NaN NaN NaN NaN NaN 2013-01-02 NaN NaN NaN NaN NaN 2013-01-03 -1.575200 -1.442130 -1.154726 4.0 1.0 2013-01-04 -2.490150 -2.198955 -2.984590 2.0 0.0 2013-01-05 -3.596231 -3.808327 -6.332947 0.0 -1.0 2013-01-06 NaN NaN NaN NaN NaN 5-2) 적용 (Apply)데이터에 함수를 적용한다. 1df.apply(np.cumsum) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2013-01-01 0.000000 0.000000 -0.545421 5 NaN 2013-01-02 0.120775 -0.572338 -2.566149 10 1.0 2013-01-03 -0.454425 -1.014468 -2.720875 15 3.0 2013-01-04 0.055426 -0.213423 -2.705465 20 6.0 2013-01-05 1.459194 0.978250 -4.038412 25 10.0 2013-01-06 2.284600 2.262070 -3.616494 30 15.0 1df.apply(lambda x: x.max() - x.min()) A 1.978968 B 1.856158 C 2.442645 D 0.000000 F 4.000000 dtype: float64 5-3) 히스토그래밍 (Histogramming)히스토그래밍과 이산화 (Value counts (histogramming) / mode) 12s = pd.Series(np.random.randint(0, 7, size=10))s 0 3 1 1 2 1 3 1 4 2 5 1 6 2 7 6 8 3 9 0 dtype: int64 1s.value_counts() 1 4 3 2 2 2 6 1 0 1 dtype: int64 5-4) 문자열 메소드 (String Methods)벡터화된 문자열 메소드 (String methods) Series는 다음의 코드와 같이 문자열 처리 메소드 모음 (set)을 가지고 있다.이 모음은 배열의 각 요소를 쉽게 조작할 수 있도록 만들어주는 문자열의 속성에 포함되어 있다. 문자열의 패턴 일치 확인은 기본적으로 정규 표현식을 사용하며, 몇몇 경우에는 항상 정규 표현식을 사용함에 유의한다. 12s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])s.str.lower() 0 a 1 b 2 c 3 aaba 4 baca 5 NaN 6 caba 7 dog 8 cat dtype: object 6) 병합 (Merge)6-1) 연결 (Concat)데이터베이스 스타일 결합 (Database-style DataFrame or named Series joining/merging)결합 (join) / 병합 (merge) 형태의 연산에 대한 인덱스, 관계 대수 기능을 위한 다양한 형태의 논리를 포함한 Series, 데이터프레임, Panel 객체를 손쉽게 결합할 수 있도록 하는 다양한 기능을 pandas 에서 제공한다.concat()으로 pandas 객체를 연결한다. 12df = pd.DataFrame(np.random.randn(10, 4))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 1.279807 -1.153900 -0.582429 2.259070 1 0.532136 -0.575209 -0.042748 0.484629 2 0.531710 -0.147753 0.678086 0.120756 3 -0.533762 -0.226234 -0.250227 1.775457 4 2.162538 -0.116354 -0.521884 0.673141 5 -0.057809 -0.355782 1.148990 0.041617 6 0.765778 -0.145401 -0.604436 -1.779851 7 0.512580 0.055678 -0.070639 0.009846 8 -0.360689 1.153401 -0.377757 0.762205 9 1.038979 -0.550957 -0.740130 -0.839612 12pieces = [df[:3], df[3:7], df[7:]]pd.concat(pieces) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 1.279807 -1.153900 -0.582429 2.259070 1 0.532136 -0.575209 -0.042748 0.484629 2 0.531710 -0.147753 0.678086 0.120756 3 -0.533762 -0.226234 -0.250227 1.775457 4 2.162538 -0.116354 -0.521884 0.673141 5 -0.057809 -0.355782 1.148990 0.041617 6 0.765778 -0.145401 -0.604436 -1.779851 7 0.512580 0.055678 -0.070639 0.009846 8 -0.360689 1.153401 -0.377757 0.762205 9 1.038979 -0.550957 -0.740130 -0.839612 6-2) 결합 (Join)SQL 방식으로 병합한다. 12left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})left .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval 0 foo 1 1 foo 2 12right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key rval 0 foo 4 1 foo 5 1pd.merge(left, right, on= 'key') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval rval 0 foo 1 4 1 foo 1 5 2 foo 2 4 3 foo 2 5 다른 예시이다. 12left = pd.DataFrame({'key' : ['foo', 'bar'], 'lval' : [1, 2]})left .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval 0 foo 1 1 bar 2 12right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key rval 0 foo 4 1 bar 5 1pd.merge(left, right, on= 'key') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval rval 0 foo 1 4 1 bar 2 5 6-3) 추가 (Append)Appending rows to a DataFrame데이터프레임에 행을 추가한다. 12df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.061291 1.294748 1.034918 1.133735 1 0.350266 0.612054 -0.184834 -0.349107 2 0.161551 1.173609 1.759626 -0.416150 3 0.208048 2.164734 -0.798397 1.449171 4 -0.777391 -1.097352 1.458079 2.725382 5 -1.336344 1.087275 0.883582 -0.455446 6 0.937276 -1.917829 0.637797 -1.077501 7 0.721358 2.959415 0.398118 -0.245919 12s = df.iloc[3]df.append(s, ignore_index=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.061291 1.294748 1.034918 1.133735 1 0.350266 0.612054 -0.184834 -0.349107 2 0.161551 1.173609 1.759626 -0.416150 3 0.208048 2.164734 -0.798397 1.449171 4 -0.777391 -1.097352 1.458079 2.725382 5 -1.336344 1.087275 0.883582 -0.455446 6 0.937276 -1.917829 0.637797 -1.077501 7 0.721358 2.959415 0.398118 -0.245919 8 0.208048 2.164734 -0.798397 1.449171 7) 그룹화 (Grouping)그룹화(Group by: split-apply-combine)는 다음 단계 중 하나 이상을 포함하는 과정을 가리킨다. 몇몇 기준에 따라 여러 그룹으로 데이터를 분할 (splitting) 각 그룹에 독립적으로 함수를 적용 (applying) 결과물들을 하나의 데이터 구조로 결합 (combining) 12345678df = pd.DataFrame( { 'A' : ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'], 'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'], 'C' : np.random.randn(8), 'D' : np.random.randn(8) })df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 foo one -0.531629 -0.841219 1 bar one 0.847370 -0.702148 2 foo two -3.025496 -0.458174 3 bar three -0.317416 -1.938912 4 foo two -0.128090 -0.880979 5 bar two -1.918498 0.091863 6 foo one -1.142854 0.159617 7 foo three -1.046234 0.334159 생성된 데이터프레임을 그룹화한 후 각 그룹에 sum() 함수를 적용한다. 1df.groupby('A').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C D A bar -1.388545 -2.549197 foo -5.874302 -1.686597 여러 열을 기준으로 그룹화하면 계층적 인덱스가 형성된다.여기에도 sum 함수를 적용할 수 있다. 1df.groupby(['A','B']).sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C D A B bar one 0.847370 -0.702148 three -0.317416 -1.938912 two -1.918498 0.091863 foo one -1.674483 -0.681602 three -1.046234 0.334159 two -3.153585 -1.339153 8) 변형 (Reshaping)계층적 인덱싱 (Advanced indexing with hierarchical index)변형 (Reshaping by stacking and unstacking) 8-1) 스택 (Stack)12345678tuples = list(zip(*[['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]))index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])df2 = df[:4]df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one 0.779699 -0.960938 two 1.442232 -0.931635 baz one -0.185774 -0.529952 two -0.794478 0.736231 stack() 메소드는 데이터프레임 열들의 계층을 “압축”한다. 12stacked = df2.stack()stacked first second bar one A 0.779699 B -0.960938 two A 1.442232 B -0.931635 baz one A -0.185774 B -0.529952 two A -0.794478 B 0.736231 dtype: float64 “Stack된” 데이터프레임 또는 (MultiIndex를 인덱스로 사용하는) Series인 경우, stack()의 역 연산은 unstack()이며, 기본적으로 마지막 계층을 unstack합니다. 1stacked.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one 0.779699 -0.960938 two 1.442232 -0.931635 baz one -0.185774 -0.529952 two -0.794478 0.736231 1stacked.unstack(1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } second one two first bar A 0.779699 1.442232 B -0.960938 -0.931635 baz A -0.185774 -0.794478 B -0.529952 0.736231 1stacked.unstack(0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } first bar baz second one A 0.779699 -0.185774 B -0.960938 -0.529952 two A 1.442232 -0.794478 B -0.931635 0.736231 8-2) 피벗 테이블 (Pivot Tables)Reshaping by pivoting DataFrame objects 123456df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3, 'B' : ['A', 'B', 'C'] * 4, 'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2, 'D' : np.random.randn(12), 'E' : np.random.randn(12)})df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 0 one A foo -0.388590 -0.092924 1 one B foo 0.096758 -1.404417 2 two C foo 0.235439 -1.441384 3 three A bar 1.644634 -1.404461 4 one B bar -0.137766 -0.732040 5 one C bar -0.385584 0.876041 6 two A foo -1.144518 1.714938 7 three B foo -0.287536 0.984071 8 one C foo 0.670096 -0.093942 9 one A bar -0.540043 -0.589907 10 two B bar 1.116471 1.360887 11 three C bar -0.751042 0.641450 1pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C bar foo A B one A -0.540043 -0.388590 B -0.137766 0.096758 C -0.385584 0.670096 three A 1.644634 NaN B NaN -0.287536 C -0.751042 NaN two A NaN -1.144518 B 1.116471 NaN C NaN 0.235439 9) 시계열 (Time Series)시계열 (Time series / date functionality)Pandas는 자주 일어나는 변환 (예시 : 5분마다 일어나는 데이터에 대한 2차 데이터 변환) 사이에 수행하는 리샘플링 연산을 위한 간단하고, 강력하며, 효율적인 함수를 제공한다. 이는 재무 (금융) 응용에서 매우 일반적이지만 이에 국한되지는 않는다. 123rng = pd.date_range('1/1/2012', periods=100, freq='S')ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)ts.resample('5Min').sum() 2012-01-01 27558 Freq: 5T, dtype: int64 시간대를 표현한다. 123rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')ts = pd.Series(np.random.randn(len(rng)), rng)ts 2012-03-06 1.212536 2012-03-07 0.751280 2012-03-08 1.779794 2012-03-09 -0.981566 2012-03-10 0.161867 Freq: D, dtype: float64 12ts_utc = ts.tz_localize('UTC')ts_utc 2012-03-06 00:00:00+00:00 1.212536 2012-03-07 00:00:00+00:00 0.751280 2012-03-08 00:00:00+00:00 1.779794 2012-03-09 00:00:00+00:00 -0.981566 2012-03-10 00:00:00+00:00 0.161867 Freq: D, dtype: float64 다른 시간대로 변환한다. 1ts_utc.tz_convert('US/Eastern') 2012-03-05 19:00:00-05:00 1.212536 2012-03-06 19:00:00-05:00 0.751280 2012-03-07 19:00:00-05:00 1.779794 2012-03-08 19:00:00-05:00 -0.981566 2012-03-09 19:00:00-05:00 0.161867 Freq: D, dtype: float64 시간 표현 ↔ 기간 표현으로 변환한다. 123rng = pd.date_range('1/1/2012', periods=5, freq='M')ts = pd.Series(np.random.randn(len(rng)), index=rng)ts 2012-01-31 -1.147594 2012-02-29 2.187776 2012-03-31 -0.567851 2012-04-30 1.944352 2012-05-31 -0.638937 Freq: M, dtype: float64 12ps = ts.to_period()ps 2012-01 -1.147594 2012-02 2.187776 2012-03 -0.567851 2012-04 1.944352 2012-05 -0.638937 Freq: M, dtype: float64 1ps.to_timestamp() 2012-01-01 -1.147594 2012-02-01 2.187776 2012-03-01 -0.567851 2012-04-01 1.944352 2012-05-01 -0.638937 Freq: MS, dtype: float64 기간 ↔ 시간 변환은 편리한 산술 기능들을 사용할 수 있도록 만들어준다. 다음 예제에서, 우리는 11월에 끝나는 연말 결산의 분기별 빈도를 분기말 익월의 월말일 오전 9시로 변환한다. 1234prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')ts = pd.Series(np.random.randn(len(prng)), prng)ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9ts.head() 1990-03-01 09:00 0.079946 1990-06-01 09:00 -0.277186 1990-09-01 09:00 -0.848088 1990-12-01 09:00 -0.181953 1991-03-01 09:00 -1.110753 Freq: H, dtype: float64 10) 범주화 (Categoricals)범주형 소개 (Categorical data)API 문서 (API reference)Pandas는 데이터프레임 내에 범주형 데이터를 포함할 수 있다. 가공하지 않은 성적을 범주형 데이터로 변환한다. 123df = pd.DataFrame({&quot;id&quot;:[1,2,3,4,5,6], &quot;raw_grade&quot;:['a', 'b', 'b', 'a', 'a', 'e']})df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;)df[&quot;grade&quot;] 0 a 1 b 2 b 3 a 4 a 5 e Name: grade, dtype: category Categories (3, object): ['a', 'b', 'e'] 범주에 더 의미 있는 이름을 붙여준다. (Series.cat.categories로 할당하는 것이 적합하다). 1df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;] 범주의 순서를 바꾸고 동시에 누락된 범주를 추가한다. (Series.cat에 속하는 메소드는 기본적으로 새로운 Series를 반환한다). 12df[&quot;grade&quot;] = df[&quot;grade&quot;].cat.set_categories([&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;, &quot;good&quot;, &quot;very good&quot;])df[&quot;grade&quot;] 0 very good 1 good 2 good 3 very good 4 very good 5 very bad Name: grade, dtype: category Categories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good'] 정렬은 사전 순서가 아닌, 해당 범주에서 지정된 순서대로 배열한다.(very bad, bad, medium, good, very good 의 순서로 기재되어 있기 때문에 정렬 결과도 해당 순서대로 배열된다.) 1df.sort_values(by=&quot;grade&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id raw_grade grade 5 6 e very bad 1 2 b good 2 3 b good 0 1 a very good 3 4 a very good 4 5 a very good 범주의 열을 기준으로 그룹화하면 빈 범주도 표시된다. 1df.groupby(&quot;grade&quot;).size() grade very bad 1 bad 0 medium 0 good 2 very good 3 dtype: int64 11) 그래프 (Plotting)Visualization 123ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))ts = ts.cumsum()ts.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f2486b26fd0&gt; 데이터프레임에서 plot() 메소드는 라벨이 존재하는 모든 열을 그릴 때 편리하다. 1234df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=['A', 'B', 'C', 'D']) df = df.cumsum()plt.figure(); df.plot(); plt.legend(loc='best') &lt;matplotlib.legend.Legend at 0x7f24869c8b38&gt; &lt;Figure size 432x288 with 0 Axes&gt; 12) 데이터 입/출력 (Getting Data In/Out)12-1) CSVcsv 파일에 쓴다. 1df.to_csv('foo.csv') csv 파일을 읽는다. 1pd.read_csv('foo.csv') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 A B C D 0 2000-01-01 0.360804 1.476213 -1.265585 -0.240420 1 2000-01-02 0.152304 2.910805 -0.935624 0.640792 2 2000-01-03 0.149786 3.056196 -0.101461 0.915478 3 2000-01-04 0.448929 1.637972 -0.117874 -0.625844 4 2000-01-05 0.942632 1.786469 -0.512949 -2.706819 ... ... ... ... ... ... 995 2002-09-22 -8.745917 28.871050 5.372952 -34.693096 996 2002-09-23 -8.355598 28.768257 5.388912 -33.545690 997 2002-09-24 -9.838548 28.876310 7.481758 -33.658828 998 2002-09-25 -10.267756 29.122170 7.903836 -33.454289 999 2002-09-26 -9.947559 28.628743 6.611331 -32.886421 1000 rows × 5 columns 12-2) HDF5HDF5 Store에 쓰고 읽어온다. 12df.to_hdf('foo.h5','df')pd.read_hdf('foo.h5','df') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2000-01-01 0.360804 1.476213 -1.265585 -0.240420 2000-01-02 0.152304 2.910805 -0.935624 0.640792 2000-01-03 0.149786 3.056196 -0.101461 0.915478 2000-01-04 0.448929 1.637972 -0.117874 -0.625844 2000-01-05 0.942632 1.786469 -0.512949 -2.706819 ... ... ... ... ... 2002-09-22 -8.745917 28.871050 5.372952 -34.693096 2002-09-23 -8.355598 28.768257 5.388912 -33.545690 2002-09-24 -9.838548 28.876310 7.481758 -33.658828 2002-09-25 -10.267756 29.122170 7.903836 -33.454289 2002-09-26 -9.947559 28.628743 6.611331 -32.886421 1000 rows × 4 columns 12-3) Excel엑셀 파일(MS Excel)에 쓴다. 1df.to_excel('foo.xlsx', sheet_name='Sheet1') 엑셀 파일(MS Excel)을 읽어온다. 1pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 A B C D 0 2000-01-01 0.360804 1.476213 -1.265585 -0.240420 1 2000-01-02 0.152304 2.910805 -0.935624 0.640792 2 2000-01-03 0.149786 3.056196 -0.101461 0.915478 3 2000-01-04 0.448929 1.637972 -0.117874 -0.625844 4 2000-01-05 0.942632 1.786469 -0.512949 -2.706819 ... ... ... ... ... ... 995 2002-09-22 -8.745917 28.871050 5.372952 -34.693096 996 2002-09-23 -8.355598 28.768257 5.388912 -33.545690 997 2002-09-24 -9.838548 28.876310 7.481758 -33.658828 998 2002-09-25 -10.267756 29.122170 7.903836 -33.454289 999 2002-09-26 -9.947559 28.628743 6.611331 -32.886421 1000 rows × 5 columns 13) 잡았다! (Gotchas)연산 수행 시 다음과 같은 예외 상황을 볼 수도 있다. 12if pd.Series([False, True, False]): print(&quot;I was true&quot;) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-135-5c782b38cd2f&gt; in &lt;module&gt;() ----&gt; 1 if pd.Series([False, True, False]): 2 print(&quot;I was true&quot;) /usr/local/lib/python3.6/dist-packages/pandas/core/generic.py in __nonzero__(self) 1328 def __nonzero__(self): 1329 raise ValueError( -&gt; 1330 f&quot;The truth value of a {type(self).__name__} is ambiguous. &quot; 1331 &quot;Use a.empty, a.bool(), a.item(), a.any() or a.all().&quot; 1332 ) ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). 이러한 경우에는 any(), all(), empty 등을 사용해서 무엇을 원하는지를 선택 (반영)해주어야 한다. 12if pd.Series([False, True, False])is not None: print(&quot;I was not None&quot;) I was not None","link":"/2020/11/04/study/pandas_10minutes/"}],"tags":[],"categories":[{"name":"study","slug":"study","link":"/categories/study/"}]}