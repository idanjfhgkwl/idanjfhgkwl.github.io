<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법 - 제목</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="제목"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="제목"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법(How to Choose Right Metric for Evaluating ML Model) 도입부https:&amp;#x2F;&amp;#x2F;www.kaggle.com&amp;#x2F;vipulgandhi&amp;#x2F;how-to-choose-right-metric-for-evaluating-ml-model 이 Scikit-learn 페이지는 훌륭한"><meta property="og:type" content="blog"><meta property="og:title" content="ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법"><meta property="og:url" content="https://github.com/idanjfhgkwl/idanjfhgkwl.github.io/2020/12/01/study/kaggle_how_to_choose_right_metric_for_evaluating_ml_model_vipulgandhi/"><meta property="og:site_name" content="제목"><meta property="og:description" content="ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법(How to Choose Right Metric for Evaluating ML Model) 도입부https:&amp;#x2F;&amp;#x2F;www.kaggle.com&amp;#x2F;vipulgandhi&amp;#x2F;how-to-choose-right-metric-for-evaluating-ml-model 이 Scikit-learn 페이지는 훌륭한"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://user-images.githubusercontent.com/72365720/100689145-3b388380-33c7-11eb-9f61-aec4666ba452.png"><meta property="article:published_time" content="2020-12-01T02:54:47.536Z"><meta property="article:modified_time" content="2020-12-01T02:54:47.827Z"><meta property="article:author" content="JustY"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://user-images.githubusercontent.com/72365720/100689145-3b388380-33c7-11eb-9f61-aec4666ba452.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://github.com/idanjfhgkwl/idanjfhgkwl.github.io/2020/12/01/study/kaggle_how_to_choose_right_metric_for_evaluating_ml_model_vipulgandhi/"},"headline":"제목","image":["https://user-images.githubusercontent.com/72365720/100689145-3b388380-33c7-11eb-9f61-aec4666ba452.png"],"datePublished":"2020-12-01T02:54:47.536Z","dateModified":"2020-12-01T02:54:47.827Z","author":{"@type":"Person","name":"JustY"},"description":"ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법(How to Choose Right Metric for Evaluating ML Model) 도입부https:&#x2F;&#x2F;www.kaggle.com&#x2F;vipulgandhi&#x2F;how-to-choose-right-metric-for-evaluating-ml-model 이 Scikit-learn 페이지는 훌륭한"}</script><link rel="canonical" href="https://github.com/idanjfhgkwl/idanjfhgkwl.github.io/2020/12/01/study/kaggle_how_to_choose_right_metric_for_evaluating_ml_model_vipulgandhi/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="제목" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-01T02:54:47.536Z" title="2020-12-01T02:54:47.536Z">2020-12-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-12-01T02:54:47.827Z" title="2020-12-01T02:54:47.827Z">2020-12-01</time></span><span class="level-item"><a class="link-muted" href="/categories/study/">study</a></span><span class="level-item">19 minutes read (About 2812 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법</h1><div class="content"><h1 id="ML-모델-을-평가하기-위한-올바른-측정-항목을-선택하는-방법"><a href="#ML-모델-을-평가하기-위한-올바른-측정-항목을-선택하는-방법" class="headerlink" title="ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법"></a>ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법</h1><p>(How to Choose Right Metric for Evaluating ML Model)</p>
<h2 id="도입부"><a href="#도입부" class="headerlink" title="도입부"></a>도입부</h2><p><a target="_blank" rel="noopener" href="https://www.kaggle.com/vipulgandhi/how-to-choose-right-metric-for-evaluating-ml-model">https://www.kaggle.com/vipulgandhi/how-to-choose-right-metric-for-evaluating-ml-model</a></p>
<p>이 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/model_evaluation.html">Scikit-learn 페이지</a>는 훌륭한 참조를 제공합니다.</p>
<p>일반적인 기능 엔지니어링, 선택, 모델 구현을 수행하고 확률 또는 클래스 형태로 출력을 얻은 후 다음 단계는 테스트 데이터 세트를 사용하여 일부 메트릭을 기반으로 모델이 얼마나 효과적인지 확인하는 것입니다. 메트릭은 모델의 성능을 설명합니다.<br><br><br>모델은 정확도 _ 점수라는 메트릭을 사용하여 평가할 때 만족스러운 결과를 제공 할 수 있지만 logarithmic_loss와 같은 다른 메트릭 또는 다른 이러한 메트릭에 대해 평가할 때 좋지 않은 결과를 제공 할 수 있습니다. 따라서 기계 학습 모델을 평가하기 위해 올바른 메트릭을 선택하는 것이 매우 중요합니다.<br><br><br>측정 항목 선택은 기계 학습 알고리즘의 성능을 측정하고 비교하는 방법에 영향을줍니다. 결과에서 다른 특성의 중요성에 가중치를 부여하는 방법에 영향을줍니다.<br><br><br><strong>분류 메트릭</strong></p>
<ul>
<li>정확성.</li>
<li>대수 손실.</li>
<li>ROC, AUC.</li>
<li>혼란 매트릭스.</li>
<li>분류 보고서.</li>
</ul>
<p><strong>회귀 지표</strong></p>
<ul>
<li>평균 절대 오차.</li>
<li>평균 제곱 오차.</li>
<li>평균 제곱근 오차.</li>
<li>루트 평균 제곱 로그 오류.</li>
<li>R 광장.</li>
<li>R 제곱을 조정했습니다.</li>
</ul>
<p><strong>분류 문제</strong>에서는 , 우리는 (자신이 생성 출력의 종류에 따라) 알고리즘의 두 가지 유형을 사용</p>
<ul>
<li><strong>클래스 출력</strong> : SVM 및 KNN과 같은 알고리즘은 클래스 출력을 생성합니다. 예를 들어, 이진 분류 문제에서 출력은 0 또는 1입니다. SKLearn의 / 기타 알고리즘은 이러한 클래스 출력을 확률로 변환 할 수 있습니다.</li>
<li><strong>확률 출력</strong> : 로지스틱 회귀, 랜덤 포레스트, 그라디언트 부스팅, Adaboost 등과 같은 알고리즘은 확률 출력을 제공합니다. 확률 출력은 임계 확률을 생성하여 클래스 출력으로 변환 할 수 있습니다.</li>
</ul>
<p>회귀 문제에서 출력은 본질적으로 항상 연속적이며 추가 처리가 필요하지 않습니다.</p>
<h2 id="분류-메트릭"><a href="#분류-메트릭" class="headerlink" title="분류 메트릭"></a>분류 메트릭</h2><p>(Classification Metrices)</p>
<ul>
<li>데이터 세트 : 피마 인디언 당뇨병 예측.  </li>
<li>평가 알고리즘 : 로지스틱 회귀, SGDClassifier, RandomForestClassifier.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive <span class="comment"># 패키지 불러오기 </span></span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 구글 드라이브 마운트</span></span><br><span class="line">ROOT = <span class="string">&quot;/content/drive&quot;</span>     <span class="comment"># 드라이브 기본 경로</span></span><br><span class="line">print(ROOT)                 <span class="comment"># print content of ROOT (Optional)</span></span><br><span class="line">drive.mount(ROOT)           <span class="comment"># 드라이브 기본 경로 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 프로젝트 파일 생성 및 다운받을 경로 이동</span></span><br><span class="line">MY_GOOGLE_DRIVE_PATH = <span class="string">&#x27;My Drive/Colab Notebooks/python_basic/kaggle_how-to-choose-right-metric-for-evaluating-ml-model_vipulgandhi/data&#x27;</span></span><br><span class="line">PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)</span><br><span class="line">print(PROJECT_PATH)</span><br></pre></td></tr></table></figure>

<pre><code>/content/drive
Mounted at /content/drive
/content/drive/My Drive/Colab Notebooks/python_basic/kaggle_how-to-choose-right-metric-for-evaluating-ml-model_vipulgandhi/data</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%cd <span class="string">&quot;&#123;PROJECT_PATH&#125;&quot;</span></span><br></pre></td></tr></table></figure>

<pre><code>/content/drive/My Drive/Colab Notebooks/python_basic/kaggle_how-to-choose-right-metric-for-evaluating-ml-model_vipulgandhi/data</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!ls</span><br></pre></td></tr></table></figure>

<pre><code>diabetes.csv</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression, SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, cross_val_score, cross_val_predict, StratifiedKFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">diabetes_data = pd.read_csv(<span class="string">&#x27;diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X =  diabetes_data.drop([<span class="string">&quot;Outcome&quot;</span>],axis = <span class="number">1</span>)</span><br><span class="line">y = diabetes_data[<span class="string">&quot;Outcome&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트를 사용하여 다양한 하이퍼 파라미터로 여러 모델을 훈련하고 검증 세트에서 가장 잘 수행되는 모델과 하이퍼 파라미터를 선택합니다.</span></span><br><span class="line"><span class="comment"># 모델 유형과 하이퍼 파라미터가 선택되면 전체 훈련 세트에서 이러한 하이퍼 파라미터를 사용하여 최종 모델을 훈련시키고 일반화 된 오류는 테스트 세트에서 최종적으로 측정됩니다.</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = <span class="number">56</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># StratifiedKFold 클래스는 계층화 된 샘플링을 수행하여 각 클래스의 대표 비율을 포함하는 폴드를 생성합니다.</span></span><br><span class="line">cv = StratifiedKFold(n_splits=<span class="number">10</span>, shuffle = <span class="literal">False</span>, random_state = <span class="number">76</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 로지스틱 회귀</span></span><br><span class="line">clf_logreg = LogisticRegression()</span><br><span class="line"><span class="comment"># 적합 모델</span></span><br><span class="line">clf_logreg.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 검증 세트에 대한 클래스 예측을합니다.</span></span><br><span class="line">y_pred_class_logreg = cross_val_predict(clf_logreg, X_train, y_train, cv = cv)</span><br><span class="line"><span class="comment"># 클래스 1에 대한 예측 확률, 양성 클래스의 확률</span></span><br><span class="line">y_pred_prob_logreg = cross_val_predict(clf_logreg, X_train, y_train, cv = cv, method=<span class="string">&quot;predict_proba&quot;</span>)</span><br><span class="line">y_pred_prob_logreg_class1 = y_pred_prob_logreg[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># SGD 분류기</span></span><br><span class="line">clf_SGD = SGDClassifier()</span><br><span class="line"><span class="comment"># 적합 모델</span></span><br><span class="line">clf_SGD.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 검증 세트에 대한 클래스 예측을합니다.</span></span><br><span class="line">y_pred_class_SGD = cross_val_predict(clf_SGD, X_train, y_train, cv = cv)</span><br><span class="line"><span class="comment"># 클래스 1에 대한 예측 확률</span></span><br><span class="line">y_pred_prob_SGD = cross_val_predict(clf_SGD, X_train, y_train, cv = cv, method=<span class="string">&quot;decision_function&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 랜덤 포레스트 분류기</span></span><br><span class="line">clf_rfc = RandomForestClassifier()</span><br><span class="line"><span class="comment"># 적합 모델</span></span><br><span class="line">clf_rfc.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 검증 세트에 대한 클래스 예측을합니다.</span></span><br><span class="line">y_pred_class_rfc = cross_val_predict(clf_rfc, X_train, y_train, cv = cv)</span><br><span class="line"><span class="comment"># 클래스 1에 대한 예측 확률</span></span><br><span class="line">y_pred_prob_rfc = cross_val_predict(clf_rfc, X_train, y_train, cv = cv, method=<span class="string">&quot;predict_proba&quot;</span>)</span><br><span class="line">y_pred_prob_rfc_class1 = y_pred_prob_rfc[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p><strong>빠른 참고</strong> : SkLearn의 “predict_log_proba”는 확률의 로그를 제공합니다. 확률이 매우 작아 질 수 있으므로 종종 더 편리합니다.</p>
<h3 id="Null-정확도"><a href="#Null-정확도" class="headerlink" title="Null 정확도"></a>Null 정확도</h3><p>(Null accuracy)</p>
<ul>
<li>항상 가장 빈번한 클래스를 예측하여 얻을 수있는 정확도.</li>
<li>이것은 항상 0/1을 예측하는 멍청한 모델이 “null_accuracy”%의 시간에 맞을 것이라는 것을 의미합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseClassifier</span>(<span class="params">BaseEstimator</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.zeros((<span class="built_in">len</span>(X), <span class="number">1</span>), dtype=<span class="built_in">bool</span>)</span><br><span class="line">    </span><br><span class="line">base_clf = BaseClassifier()</span><br><span class="line">cross_val_score(base_clf, X_train, y_train, cv=<span class="number">10</span>, scoring=<span class="string">&quot;accuracy&quot;</span>).mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2</span></span><br><span class="line"><span class="comment"># calculate null accuracy (for binary / multi-class classification problems)</span></span><br><span class="line"><span class="comment"># null_accuracy = y_train.value_counts().head(1) / len(y_train)</span></span><br></pre></td></tr></table></figure>




<pre><code>0.6509981851179674</code></pre>
<h3 id="분류-정확도"><a href="#분류-정확도" class="headerlink" title="분류 정확도"></a>분류 정확도</h3><p>(Classification Accuracy)</p>
<p>분류 정확도 또는 정확도는 총 입력 샘플 수에 대한 올바른 예측 수의 비율입니다.  </p>
<p>$$Accuracy = \frac{Number\ of\ correct\ predictions}{Total\ number\ of\ predictions\ made} = \frac{TP + TN}{TP + TN + FP + FN}$$<br><img src="https://user-images.githubusercontent.com/72365720/100689145-3b388380-33c7-11eb-9f61-aec4666ba452.png" alt="다운로드">  </p>
<p>정확도 측정 항목을 사용하는 경우: 각 클래스에 속하는 샘플 수가 거의 동일한 경우<br>정확도 측정 항목을 사용하지 않는 경우: 하나의 클래스 만 대부분의 샘플을 보유 할 때.<br><br><br><strong>예</strong>:<br>훈련 세트에 클래스 A의 샘플이 98 %이고 클래스 B의 샘플이 2 %라고 가정합니다. 그러면 우리 모델은 클래스 A에 속하는 모든 훈련 샘플을 간단히 예측하여 98 %의 훈련 정확도를 쉽게 얻을 수 있습니다.<br>동일한 모델이 클래스 A의 60 % 샘플과 클래스 B의 40 % 샘플이있는 테스트 세트에서 테스트되면 테스트 정확도가 60 %로 떨어집니다. 분류 정확도는 우리에게 높은 정확도를 달성한다는 잘못된 감각을 줄 수 있습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 정확도 계산</span></span><br><span class="line"></span><br><span class="line">acc_logreg = cross_val_score(clf_logreg, X_train, y_train, cv = cv, scoring = <span class="string">&#x27;accuracy&#x27;</span>).mean()</span><br><span class="line">acc_SGD = cross_val_score(clf_SGD, X_train, y_train, cv = cv, scoring = <span class="string">&#x27;accuracy&#x27;</span>).mean()</span><br><span class="line">acc_rfc = cross_val_score(clf_rfc, X_train, y_train, cv = cv, scoring = <span class="string">&#x27;accuracy&#x27;</span>).mean()</span><br><span class="line"></span><br><span class="line">acc_logreg, acc_SGD, acc_rfc</span><br></pre></td></tr></table></figure>




<pre><code>(0.7797035692679977, 0.611222020568663, 0.7606473079249849)</code></pre>
<h3 id="로그-손실-로그-손실-로지스틱-손실-교차-엔트로피-손실"><a href="#로그-손실-로그-손실-로지스틱-손실-교차-엔트로피-손실" class="headerlink" title="로그 손실 / 로그 손실 / 로지스틱 손실 / 교차 엔트로피 손실"></a>로그 손실 / 로그 손실 / 로지스틱 손실 / 교차 엔트로피 손실</h3><ul>
<li>로그 손실로 작업 할 때 분류기는 모든 샘플에 대해 각 클래스에 확률을 할당해야합니다.</li>
<li>로그 손실은 실제 레이블과 비교하고 잘못된 분류에 페널티를 적용하여 모델 확률의 불확실성을 측정합니다.</li>
<li>로그 손실은 둘 이상의 레이블에 대해서만 정의됩니다.</li>
<li>로그 손실은 예측 확률이 향상됨에 따라 점차 감소하므로 로그 손실이 0에 가까울수록 정확도가 높아지고 로그 손실이 0에서 멀어지면 정확도가 낮아집니다.</li>
<li>로그 손실은 (0, ∞] 범위에 있습니다.</li>
</ul>
<p>M 클래스에 속하는 N 개의 샘플이 있다고 가정하면 로그 손실은 다음과 같이 계산됩니다.<br>$$ Log\ Loss = \frac{-1}{N} \sum_{i=1}^{N} \sum_{i=1}^{M}  y_{ij} * \log(\hat{y_{ij}})$$   </p>
<ul>
<li>$y_{ij}$ ,샘플 i가 클래스 j에 속하는지 여부를 나타냅니다.</li>
<li>$p_{ij}$ ,샘플 i가 클래스 j에 속하는 확률을 나타냅니다.</li>
</ul>
<p>음수 부호 부정  $\log(\hat{y_{ij}})$  항상 음수 인 출력.  $\hat{y_{ij}}$  확률 (0-1)을 출력하고,  $\log(x)$  0 &lt;x &lt;1 인 경우 음수입니다.  </p>
<p><strong>예</strong>:<br>학습 레이블은 0과 1이지만 학습 예측은 0.4, 0.6, 0.89 등입니다. 모델의 오류 측정 값을 계산하기 위해 0.5보다 큰 값을 갖는 모든 관측 값을 1로 분류 할 수 있습니다. 우리는 오 분류를 증가시킬 위험이 높습니다. 확률이 0.4, 0.45, 0.49 인 많은 값이 1의 참값을 가질 수 있기 때문입니다.<br>이것이 logLoss가 등장하는 곳입니다.<br>이제 LogLoss의 공식을 자세히 살펴 보겠습니다. 값에 대한 4 가지 주요 사례가있을 수 있습니다. $y_{ij}$  과  $p_{ij}$ </p>
<ul>
<li>사례 1 :  $y_{ij}$j =1 ,  $p_{ij}$  = 높음</li>
<li>사례 2 :  $y_{ij}$ =1 ,  $p_{ij}$  = 낮음</li>
<li>사례 3 :  $y_{ij}$ =0 ,  $p_{ij}$  = 낮음</li>
<li>사례 4 :  $y_{ij}$ =0 ,  $p_{ij}$  = 높음</li>
</ul>
<p>LogLoss는 불확실성을 어떻게 측정합니까?<br>케이스 1과 케이스 3이 더 많이있는 경우 로그 로스 공식 내부의 합계 (및 평균)는 케이스 2와 케이스 4가 추가 된 경우에 비해 훨씬 더 커질 것입니다. 이제이 값은 좋은 예측을 나타내는 Case 1 및 Case 3만큼 큽니다. (-1)을 곱하면 값을 가능한 한 작게 만듭니다. 이것은 이제 직관적으로 의미합니다.-값이 작을수록 모델이 더 좋습니다. 즉, 로그 손실이 더 작고, 모델이 더 좋습니다. 즉, 불확실성이 더 작고, 모델이 더 좋습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># logloss 계산</span></span><br><span class="line"></span><br><span class="line">logloss_logreg = cross_val_score(clf_logreg, X_train, y_train, cv = cv, scoring = <span class="string">&#x27;neg_log_loss&#x27;</span>).mean()</span><br><span class="line">logloss_rfc = cross_val_score(clf_rfc, X_train, y_train, cv = cv, scoring = <span class="string">&#x27;neg_log_loss&#x27;</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># SGDClassifier의 힌지 손실은 확률 추정을 지원하지 않습니다.</span></span><br><span class="line"><span class="comment"># Scikit-learn의 CalibratedClassifierCV에서 SGDClassifier를 기본 추정기로 설정하여 확률 추정치를 생성 할 수 있습니다.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.calibration <span class="keyword">import</span> CalibratedClassifierCV</span><br><span class="line"></span><br><span class="line">new_clf_SGD = CalibratedClassifierCV(clf_SGD)</span><br><span class="line">new_clf_SGD.fit(X_train, y_train)</span><br><span class="line">logloss_SGD = cross_val_score(new_clf_SGD, X_train, y_train, cv = cv, scoring = <span class="string">&#x27;neg_log_loss&#x27;</span>).mean()</span><br><span class="line"></span><br><span class="line">logloss_logreg, logloss_SGD, logloss_rfc</span><br></pre></td></tr></table></figure>




<pre><code>(-0.48368646454082465, -0.6383384003043665, -0.4664817973667718)</code></pre>
<h3 id="ROC-곡선"><a href="#ROC-곡선" class="headerlink" title="ROC 곡선"></a>ROC 곡선</h3><h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><h3 id="혼동-매트릭스"><a href="#혼동-매트릭스" class="headerlink" title="혼동 매트릭스"></a>혼동 매트릭스</h3><h3 id="분류-보고서"><a href="#분류-보고서" class="headerlink" title="분류 보고서"></a>분류 보고서</h3><h3 id="정밀도-재현율-트레이드-오프"><a href="#정밀도-재현율-트레이드-오프" class="headerlink" title="정밀도-재현율 트레이드 오프"></a>정밀도-재현율 트레이드 오프</h3><h3 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h3><h2 id="회귀-지표"><a href="#회귀-지표" class="headerlink" title="회귀 지표"></a>회귀 지표</h2><h3 id="평균-절대-오차"><a href="#평균-절대-오차" class="headerlink" title="평균 절대 오차"></a>평균 절대 오차</h3><h3 id="평균-제곱-오차"><a href="#평균-제곱-오차" class="headerlink" title="평균 제곱 오차"></a>평균 제곱 오차</h3><h3 id="RMSE"><a href="#RMSE" class="headerlink" title="RMSE"></a>RMSE</h3><h3 id="평균-제곱근-로그-오차"><a href="#평균-제곱근-로그-오차" class="headerlink" title="평균 제곱근 로그 오차"></a>평균 제곱근 로그 오차</h3><h3 id="R-제곱"><a href="#R-제곱" class="headerlink" title="R_ 제곱"></a>R_ 제곱</h3><h3 id="조정-된-R-제곱"><a href="#조정-된-R-제곱" class="headerlink" title="조정 된 R- 제곱"></a>조정 된 R- 제곱</h3><h2 id="NLP-메트릭"><a href="#NLP-메트릭" class="headerlink" title="NLP 메트릭"></a>NLP 메트릭</h2><h2 id="보너스"><a href="#보너스" class="headerlink" title="보너스"></a>보너스</h2><h3 id="다중-클래스-분류"><a href="#다중-클래스-분류" class="headerlink" title="다중 클래스 분류"></a>다중 클래스 분류</h3><h3 id="다중-라벨-분류"><a href="#다중-라벨-분류" class="headerlink" title="다중 라벨 분류"></a>다중 라벨 분류</h3><h3 id="다중-출력-분류"><a href="#다중-출력-분류" class="headerlink" title="다중 출력 분류"></a>다중 출력 분류</h3></div><div class="article-licensing box"><div class="licensing-title"><p>ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법</p><p><a href="https://github.com/idanjfhgkwl/idanjfhgkwl.github.io/2020/12/01/study/kaggle_how_to_choose_right_metric_for_evaluating_ml_model_vipulgandhi/">https://github.com/idanjfhgkwl/idanjfhgkwl.github.io/2020/12/01/study/kaggle_how_to_choose_right_metric_for_evaluating_ml_model_vipulgandhi/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>JustY</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-12-01</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2020-12-01</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" href="/" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>Afdian.net</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/12/03/study/python_machine_learning_perfect_guide_ch05/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">파이썬 머신러닝 완벽가이드 5장</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/12/01/study/Tour_of_Evaluation_Metrics_for_Imbalanced_Classification/"><span class="level-item">불균형 분류에 대한 평가 지표 둘러보기 (번역)</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/study/"><span class="level-start"><span class="level-item">study</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-04T00:37:02.928Z">2020-12-04</time></p><p class="title"><a href="/2020/12/04/study/python_machine_learning_perfect_guide_ch06/">파이썬 머신러닝 완벽가이드 6장</a></p><p class="categories"><a href="/categories/study/">study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-03T06:49:25.640Z">2020-12-03</time></p><p class="title"><a href="/2020/12/03/study/python_machine_learning_perfect_guide_ch03/">파이썬 머신러닝 완벽가이드 3장</a></p><p class="categories"><a href="/categories/study/">study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-03T06:46:46.253Z">2020-12-03</time></p><p class="title"><a href="/2020/12/03/study/python_machine_learning_perfect_guide_ch04/">파이썬 머신러닝 완벽가이드 4장</a></p><p class="categories"><a href="/categories/study/">study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-03T06:41:16.887Z">2020-12-03</time></p><p class="title"><a href="/2020/12/03/study/python_machine_learning_perfect_guide_ch05/">파이썬 머신러닝 완벽가이드 5장</a></p><p class="categories"><a href="/categories/study/">study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-01T02:54:47.536Z">2020-12-01</time></p><p class="title"><a href="/2020/12/01/study/kaggle_how_to_choose_right_metric_for_evaluating_ml_model_vipulgandhi/">ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법</a></p><p class="categories"><a href="/categories/study/">study</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="제목" height="28"></a><p class="is-size-7"><span>&copy; 2020 JustY</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>